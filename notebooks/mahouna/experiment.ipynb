{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58a66b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e14015ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "full_dataset = datasets.ImageFolder(\"../../data\", transform=transform)\n",
    "\n",
    "keep_classes = [\"Forest\", \"Residential\"]\n",
    "keep_indices = [i for i, (_, label) in enumerate(full_dataset) if full_dataset.classes[label] in keep_classes]\n",
    "subset = Subset(full_dataset, keep_indices)\n",
    "\n",
    "class_map = {\n",
    "    full_dataset.class_to_idx[\"Forest\"]: 0,\n",
    "    full_dataset.class_to_idx[\"Residential\"]: 1\n",
    "}\n",
    "\n",
    "class RelabeledDataset(Dataset):\n",
    "    def __init__(self, subset, class_map):\n",
    "        self.subset = subset\n",
    "        self.class_map = class_map\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.subset[idx]\n",
    "        return x, self.class_map[y]\n",
    "\n",
    "dataset = RelabeledDataset(subset, class_map)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04141e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800 1200\n",
      "['Forest', 'OOD', 'Residential']\n",
      "Labels présents dans le dataset : [0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ds), len(val_ds))\n",
    "print(full_dataset.classes)\n",
    "\n",
    "import torch\n",
    "\n",
    "all_labels = [y for _, y in dataset]\n",
    "unique_labels = torch.unique(torch.tensor(all_labels))\n",
    "print(\"Labels présents dans le dataset :\", unique_labels.tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "730c8acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 8 * 8, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "model = CNNClassifier().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ed6a08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=30, patience=5):\n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "    history = {\"train_loss\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, correct = 0.0, 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * imgs.size(0)\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = correct / len(val_loader.dataset)\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = model.state_dict()\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_model)\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75b016e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30] | Train Loss: 0.0431 | Val Loss: 0.0105 | Val Acc: 0.9950\n",
      "Epoch [2/30] | Train Loss: 0.0093 | Val Loss: 0.0206 | Val Acc: 0.9925\n",
      "Epoch [3/30] | Train Loss: 0.0103 | Val Loss: 0.0163 | Val Acc: 0.9950\n",
      "Epoch [4/30] | Train Loss: 0.0055 | Val Loss: 0.0033 | Val Acc: 0.9992\n",
      "Epoch [5/30] | Train Loss: 0.0033 | Val Loss: 0.0101 | Val Acc: 0.9958\n",
      "Epoch [6/30] | Train Loss: 0.0070 | Val Loss: 0.0067 | Val Acc: 0.9975\n",
      "Epoch [7/30] | Train Loss: 0.0009 | Val Loss: 0.0122 | Val Acc: 0.9975\n",
      "Epoch [8/30] | Train Loss: 0.0041 | Val Loss: 0.0651 | Val Acc: 0.9875\n",
      "Epoch [9/30] | Train Loss: 0.0070 | Val Loss: 0.0066 | Val Acc: 0.9983\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "model = CNNClassifier().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "model, history = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=30, patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913bcece",
   "metadata": {},
   "source": [
    "CNN simple atteint quasi-100 % d’accuracy sur la validation avant l’arrêt précoce, donc il apprend parfaitement les deux classes et s’arrête correctement grâce à l’early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d522090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 20, 10, 10)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "import torch\n",
    "\n",
    "ood_base = ImageFolder(\"../../data/OOD\", transform=transform)\n",
    "orig_to_new = {\n",
    "    ood_base.class_to_idx[\"Forest\"]: 0,\n",
    "    ood_base.class_to_idx[\"DenseResidential\"]: 1,\n",
    "    ood_base.class_to_idx[\"MediumResidential\"]: 1,\n",
    "}\n",
    "\n",
    "class RelabeledDataset(Dataset):\n",
    "    def __init__(self, base, mapping):\n",
    "        self.base = base\n",
    "        self.mapping = mapping\n",
    "    def __len__(self):\n",
    "        return len(self.base)\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.base[idx]\n",
    "        return x, self.mapping[y]\n",
    "\n",
    "rel_ood = RelabeledDataset(ood_base, orig_to_new)\n",
    "\n",
    "idx_dense  = [i for i,(_,y) in enumerate(ood_base.samples) if y == ood_base.class_to_idx[\"DenseResidential\"]]\n",
    "idx_medium = [i for i,(_,y) in enumerate(ood_base.samples) if y == ood_base.class_to_idx[\"MediumResidential\"]]\n",
    "idx_forest = [i for i,(_,y) in enumerate(ood_base.samples) if y == ood_base.class_to_idx[\"Forest\"]]\n",
    "\n",
    "ood_loader     = DataLoader(rel_ood, batch_size=64, shuffle=False)\n",
    "dense_loader   = DataLoader(Subset(rel_ood, idx_dense),  batch_size=64, shuffle=False)\n",
    "medium_loader  = DataLoader(Subset(rel_ood, idx_medium), batch_size=64, shuffle=False)\n",
    "forest_loader  = DataLoader(Subset(rel_ood, idx_forest), batch_size=64, shuffle=False)\n",
    "\n",
    "len(ood_base), len(idx_forest), len(idx_dense), len(idx_medium)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "425eb4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    tot = 0\n",
    "    ok = 0\n",
    "    cm = torch.zeros(2,2, dtype=torch.int64)\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            logits = model(x)\n",
    "            pred = logits.argmax(1)\n",
    "            ok += (pred == y).sum().item()\n",
    "            tot += y.size(0)\n",
    "            for t,p in zip(y.cpu(), pred.cpu()):\n",
    "                cm[t, p] += 1\n",
    "    acc = ok / tot if tot else float(\"nan\")\n",
    "    return acc, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d7d03e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOD global acc: 0.775\n",
      "Forest acc: 0.55\n",
      "DenseResidential acc: 1.0\n",
      "MediumResidential acc: 1.0\n",
      "CM OOD:\n",
      " [[11  9]\n",
      " [ 0 20]]\n",
      "CM Forest:\n",
      " [[11  9]\n",
      " [ 0  0]]\n",
      "CM Dense:\n",
      " [[ 0  0]\n",
      " [ 0 10]]\n",
      "CM Medium:\n",
      " [[ 0  0]\n",
      " [ 0 10]]\n"
     ]
    }
   ],
   "source": [
    "acc_all, cm_all       = evaluate(model, ood_loader)\n",
    "acc_forest, cm_forest = evaluate(model, forest_loader)\n",
    "acc_dense, cm_dense   = evaluate(model, dense_loader)\n",
    "acc_medium, cm_medium = evaluate(model, medium_loader)\n",
    "\n",
    "print(\"OOD global acc:\", round(acc_all,4))\n",
    "print(\"Forest acc:\", round(acc_forest,4))\n",
    "print(\"DenseResidential acc:\", round(acc_dense,4))\n",
    "print(\"MediumResidential acc:\", round(acc_medium,4))\n",
    "print(\"CM OOD:\\n\", cm_all.numpy())\n",
    "print(\"CM Forest:\\n\", cm_forest.numpy())\n",
    "print(\"CM Dense:\\n\", cm_dense.numpy())\n",
    "print(\"CM Medium:\\n\", cm_medium.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae61d47",
   "metadata": {},
   "source": [
    "DenseResidential et MediumResidential sont parfaitement reconnues (100 %), mais elles sont très proches visuellement du domaine Residential d’entraînement.\n",
    "\n",
    "Forest OOD est mal reconnu (55 %), avec de nombreux faux positifs vers la classe Residential.\n",
    "\n",
    "Accuracy globale : 0.775, en forte baisse par rapport au ≈ 0.995 sur validation.\n",
    "\n",
    "→ Conclusion : le modèle classique a sur-appris la distribution d’entraînement (textures, luminosité, pattern urbain précis). Sur les forêts d’un autre domaine, il ne généralise plus."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
